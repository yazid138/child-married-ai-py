{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-10-16T13:37:05.350745Z",
     "start_time": "2024-10-16T13:37:00.303813Z"
    }
   },
   "source": "from llama_index.llms.huggingface import HuggingFaceLLM",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Project\\Python\\Child Married AI\\.venv\\lib\\site-packages\\pydantic\\_internal\\_fields.py:132: UserWarning: Field \"model_id\" in DeployedModel has conflict with protected namespace \"model_\".\n",
      "\n",
      "You may be able to resolve this warning by setting `model_config['protected_namespaces'] = ()`.\n",
      "  warnings.warn(\n",
      "D:\\Project\\Python\\Child Married AI\\.venv\\lib\\site-packages\\pydantic\\_internal\\_fields.py:132: UserWarning: Field \"model_name\" in HuggingFaceLLM has conflict with protected namespace \"model_\".\n",
      "\n",
      "You may be able to resolve this warning by setting `model_config['protected_namespaces'] = ()`.\n",
      "  warnings.warn(\n",
      "D:\\Project\\Python\\Child Married AI\\.venv\\lib\\site-packages\\pydantic\\_internal\\_fields.py:132: UserWarning: Field \"model_kwargs\" in HuggingFaceLLM has conflict with protected namespace \"model_\".\n",
      "\n",
      "You may be able to resolve this warning by setting `model_config['protected_namespaces'] = ()`.\n",
      "  warnings.warn(\n",
      "D:\\Project\\Python\\Child Married AI\\.venv\\lib\\site-packages\\pydantic\\_internal\\_fields.py:132: UserWarning: Field \"model_name\" in HuggingFaceInferenceAPI has conflict with protected namespace \"model_\".\n",
      "\n",
      "You may be able to resolve this warning by setting `model_config['protected_namespaces'] = ()`.\n",
      "  warnings.warn(\n",
      "D:\\Project\\Python\\Child Married AI\\.venv\\lib\\site-packages\\pydantic\\_internal\\_fields.py:132: UserWarning: Field \"model_name\" in TextGenerationInference has conflict with protected namespace \"model_\".\n",
      "\n",
      "You may be able to resolve this warning by setting `model_config['protected_namespaces'] = ()`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-16T13:37:30.657987Z",
     "start_time": "2024-10-16T13:37:12.467765Z"
    }
   },
   "cell_type": "code",
   "source": "locally_run = HuggingFaceLLM(model_name=\"meta-llama/Meta-Llama-3.1-8B-Instruct\")",
   "id": "35406810ab81441a",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "6beef1736b6741aaa35e049d9710f67c"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some parameters are on the meta device because they were offloaded to the cpu and disk.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/264 [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "aa7ee47804514b48acafb146523e15f1"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Project\\Python\\Child Married AI\\.venv\\lib\\site-packages\\huggingface_hub\\file_download.py:157: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\ma39i\\.cache\\huggingface\\hub\\models--StabilityAI--stablelm-tuned-alpha-3b. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to see activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/2.11M [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "fffbe4b80fd8497e92d109e2c197e48d"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/99.0 [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "542bbe1e22c848478dbe81451ca36494"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The model `meta-llama/Meta-Llama-3.1-8B-Instruct` and tokenizer `StabilityAI/stablelm-tuned-alpha-3b` are different, please ensure that they are compatible.\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-16T14:15:11.845553Z",
     "start_time": "2024-10-16T13:38:17.747504Z"
    }
   },
   "cell_type": "code",
   "source": "locally_run.complete(\"How to make a cake\")",
   "id": "50b2e6825e697be7",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Starting from v4.46, the `logits` model output will have the same type as the model (except at train time, where it will always be FP32)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "CompletionResponse(text='*ion associate----rit 2reped upSE----ionф video Cgreekileorell Howimer C\\\\\", ad\\n    C casework ins_{ withinigne Sher---- Cial Das 2 boig Says�48/+4*meion Dongook teacher clarbedolThere wasion replic Star----omaolionfficients completely* forig�/ chili�186+ars*meion6789 wasromind disease there bec IL----rom Das 2uremoreefigion immediate* shred driving wasionJust Star----ion immediate Thplace forionThere----$\\\\ Sch, tryind increasing Camp wasionpatient antagon---- immediateores* indic shgroundsion immediate Thbirds*ह wasiondule for* for ligeltaolion lis for Se immediate anc,angu– inte at plasmaigDONney* Function* for Se antagon---- immediatexxx there beenger Ext472*romindolion IL forind diseaseana revelation for User,ish speed*ion IL----rom Das 2 dynam shedatrexxx* forrominditioncremsgdummyolargsigedana followed, Ske----ionanaTL*ion IL----rom Das 2uremoremer----ion immediate Th extent for inter there bec', additional_kwargs={}, raw={'model_output': tensor([[ 2347,   281,  1056,   247, 15221,    11,   279, 15629,   315,   902,\n",
       "           374,  4762,   264, 93011,   598,  2354,   315,   279, 18341,  3492,\n",
       "           330,  8747,   587,   263,   437,  1359,  7438,   330, 31875,   519,\n",
       "             1,   477,   330,  1083,  1601,  1210,   578,  1561, 40214, 10648,\n",
       "           315,   330,   451, 23184,     1,   374,  1766,   304, 49918,   220,\n",
       "            21,    25,    16,    12,    21,    11,  1405,   279, 39571,   645,\n",
       "          9732,  8254,  3026,   311,  2512,   369,   279,  7446,  8141,   315,\n",
       "          3691,   311,   279,  9923,  4336,    11,   323,   304,   220,    16,\n",
       "         45568,   220,    18,    25,    23,    12,  1032,    11,  1405,   279,\n",
       "         43784,   369,   409, 76544,   527,  2728,   627,   791,  5274,   315,\n",
       "           409, 23184,   374,   459,  3062,   832,   304,   279,  8993,    11,\n",
       "           439,   433,  6276,   369,   279,  6300,  8141,   315,   279,  8993,\n",
       "           596,  5070,   323,   279,  2512,   315,  1202,  3697,    13,  1611,\n",
       "         76544,   527,  3629,  8647,   369,   279, 15325, 13878,   315,  8993,\n",
       "          2324,    11,  1778,   439, 18646,   279,  8993,   596, 40382,    11,\n",
       "         30598,   369,   279,  8009,   323, 83563,    11,   323,  8405,  1862,\n",
       "           311,   279, 44044,   323,  1023,  8993,  6164,    13,  2435,  1253,\n",
       "          1101,   387,  6532,   304, 39153,  2191,    11, 12917,    11,   323,\n",
       "          1023, 13878,   315,  8993, 25887,   627,   644,  1063,  9052, 32006,\n",
       "            11,   409, 76544,   527, 86724,   311,   279,  5274,   323,   527,\n",
       "          2728,  3230, 28423,   323, 11447,    13,   763,  3885,    11,   279,\n",
       "          5274,   315,   409, 23184,   374,  3970,   439,   264, 11203, 25887,\n",
       "            11,   323,   409, 76544,   527,   539, 86724,   719,  4856, 44224,\n",
       "           311,  8854,   304,   264,  3230,  3560,    13, 44840,   315,   279,\n",
       "          3230, 14135,    11,   279,  5274,   315,   409, 23184,   374,   459,\n",
       "          3062,   961,   315,   279,  8993,   596,  6070,   323,   734,   627,\n",
       "           791]])}, logprobs=None, delta=None)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 4
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
